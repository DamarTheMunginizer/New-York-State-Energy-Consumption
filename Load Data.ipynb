{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0449b765-54fe-4fd2-8088-848d27559527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "880bc11c-e4bd-4570-8cda-1793fa8a8726",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_df = pd.DataFrame(columns = ['Name','Load','Date']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0da9cea8-57e5-41f2-b261-1c51cccb39fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_data(name):\n",
    "    # Reading the file\n",
    "    df = pd.read_csv(f'data/Load Data/{name}') \n",
    "    # Extracting the date\n",
    "    df['Date'] = pd.to_datetime(df['Time Stamp']).dt.date \n",
    "    # Droping the unnecessary columns\n",
    "    df.drop(['Time Stamp','Time Zone','PTID'], axis = 1,inplace = True) \n",
    "    # Grouping the data to find avg load required and converting it to dataframe\n",
    "    gr_df = df.groupby('Name')['Load'].mean().reset_index() \n",
    "    gr_df['Date'] = df['Date']\n",
    "     # Concatenating with the global load_df\n",
    "    global load_df\n",
    "    load_df = pd.concat([load_df, gr_df], ignore_index=True)\n",
    "    return load_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6bd5e96-ca71-4111-9c1a-abb0031272b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_folder(zip_path,extract_to):\n",
    "    # Open the zip file and extract contents\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "        print(f\"Contents extracted to {extract_to}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee7a419",
   "metadata": {},
   "source": [
    "*All the data of load is taken from [New York ISO Independent Systems Operator](https://www.nyiso.com/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c94d24-9e86-4bc7-981a-9a5f0a0059c4",
   "metadata": {},
   "source": [
    "```python\n",
    "# Define the base path\n",
    "base_path = 'data/Load Data'\n",
    "\n",
    "# Iterate through the range of years\n",
    "for i in range(2008, 2025):\n",
    "    # Construct the directory path\n",
    "    directory_path = os.path.join(base_path, str(i))\n",
    "    \n",
    "    # Check if the directory exists\n",
    "    if os.path.exists(directory_path):\n",
    "        # Iterate through the files in the directory\n",
    "        for zip_file in os.listdir(directory_path):\n",
    "            # Construct the full path to the zip file\n",
    "            zip_path = os.path.join(directory_path, zip_file)\n",
    "            \n",
    "            # Call your unzip function\n",
    "            unzip_folder(zip_path, base_path)\n",
    "    else:\n",
    "        print(f\"Directory for year {i} does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f27c393-80ec-4ca4-b150-395e3128f8ed",
   "metadata": {},
   "source": [
    "#### Above code was used to extract the File which where in zip format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cb0f1ce-24ec-44ef-9aae-53d58c817491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base path\n",
    "base_path = 'data/Load Data'\n",
    "\n",
    "# Extracting the names of all the .csv files in Load Data folder\n",
    "file_names = set([i for i in os.listdir(base_path) if i.endswith('.csv')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a402e51-f820-41a1-aafe-4ca6ef5dad4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hasee\\AppData\\Local\\Temp\\ipykernel_44620\\3631843620.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  load_df = pd.concat([load_df, gr_df], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Extracting and compiling the data from all .csv files with the help of  compile_data function\n",
    "for name in file_names:\n",
    "    compile_data(name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad623c6e-e3e7-465b-9137-71cc2e2ae76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_df.to_csv('data/Newyork_state_load_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2825afe7-399e-4a86-9d44-7764e8af98b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92276, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dbee3b-049d-415d-8fb0-75c241521450",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
